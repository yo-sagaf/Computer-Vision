{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies: Run this code snippet before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def displayImage(winName, img):\n",
    "    \"\"\" Helper function to display image\n",
    "    arguments:\n",
    "    winName -- Name of display window\n",
    "    img     -- Source Image\n",
    "    \"\"\"\n",
    "    cv2.imshow(winName, img)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convolution_using_fourier_transform(image, kernel):\n",
    "    \"\"\" Helper function to filter image using Fourier Transform\n",
    "    arguments:\n",
    "    image  -- Source Image\n",
    "    kernel -- Input Kernel/Filter\n",
    "    \"\"\"\n",
    "    imageFFT = np.fft.fft2(image)\n",
    "    imageFFT = np.fft.fftshift(imageFFT)\n",
    "    kernelFFT = np.fft.fft2(kernel, image.shape)\n",
    "    kernelFFT = np.fft.fftshift(kernelFFT)\n",
    "    blurImg = np.fft.ifft2(imageFFT * kernelFFT)\n",
    "    return np.absolute(blurImg)\n",
    "\n",
    "\n",
    "def task1():\n",
    "    print('Task 1')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    image = cv2.imread('../data/einstein.jpeg', 0).astype('float64')\n",
    "    image /= 255\n",
    "    displayImage('Image', image)\n",
    "\n",
    "    # get 1-D kernel\n",
    "    kernel = cv2.getGaussianKernel(7, 1)\n",
    "    # convert to 2-D kernel\n",
    "    kernel = np.dot(kernel, np.transpose(kernel))\n",
    "\n",
    "    # calculate convolution of image and kernel\n",
    "    conv_result = cv2.filter2D(image, -1, kernel)\n",
    "    fft_result = get_convolution_using_fourier_transform(image, kernel)\n",
    "\n",
    "    displayImage('Convolution blur', conv_result)\n",
    "    displayImage('FFT blur', np.absolute(fft_result))\n",
    "\n",
    "    # compare results\n",
    "    print('Mean pixel-wise difference = ' +\n",
    "          str(np.abs(conv_result - fft_result).mean()))\n",
    "\n",
    "    print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1\n",
      "------------------------------------------------------------\n",
      "Mean pixel-wise difference = 0.0457424700050383\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "task1()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(image, template):\n",
    "    \"\"\" Helper function to match templates using NCR method\n",
    "    arguments:\n",
    "    image    -- Source Image\n",
    "    template -- Source Template\n",
    "    \"\"\"\n",
    "    h = np.zeros((image.shape[0] - template.shape[0] + 1,\n",
    "                  image.shape[1] - template.shape[1] + 1), dtype=float)\n",
    "    tempCor = (template - np.mean(template)).astype('float64')\n",
    "    for y in range(h.shape[0]):\n",
    "        for x in range(h.shape[1]):\n",
    "            imagePatch = (image[y:y+template.shape[0], x:x +\n",
    "                                template.shape[1]]).astype('float64')\n",
    "            imagePatch -= np.mean(imagePatch)\n",
    "            num = np.sum(tempCor * imagePatch)\n",
    "            denom = np.sqrt(np.sum(np.square(tempCor)) *\n",
    "                            np.sum(np.square(imagePatch)))\n",
    "            h[y, x] = num/denom\n",
    "    return h\n",
    "\n",
    "\n",
    "def task2():\n",
    "    print('Task 2')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    image = cv2.imread('../data/lena.png', 0)\n",
    "    template = cv2.imread('../data/eye.png', 0)\n",
    "    displayImage('Original Image', image)\n",
    "    displayImage('Template', template)\n",
    "\n",
    "    res = cv2.matchTemplate(image, template, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "    result_ncc = normalized_cross_correlation(image, template)\n",
    "\n",
    "    # draw rectangle around found location in all four results\n",
    "    # show the results\n",
    "    imageCustom = image.copy()\n",
    "\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(res)\n",
    "    # The opencv mapping matrix seems weird compared to the custom one. Unable to use the same logic\n",
    "    # as that used in Customer to filter bounding boxes\n",
    "    cv2.rectangle(\n",
    "        image, max_loc, (max_loc[0] + template.shape[0], max_loc[1] + template.shape[1]), 255, 2)\n",
    "    displayImage('OpenCV Match Template', image)\n",
    "\n",
    "    boundingBoxCustom = np.where(result_ncc >= 0.7)\n",
    "    for i in range(len(boundingBoxCustom[0])):\n",
    "        topLeft = (boundingBoxCustom[0][i], boundingBoxCustom[1][i])\n",
    "        bottomRight = (boundingBoxCustom[0][i] + template.shape[0],\n",
    "                       boundingBoxCustom[1][i] + template.shape[1])\n",
    "        cv2.rectangle(imageCustom, topLeft, bottomRight, 255, 2)\n",
    "    displayImage('Custom Match Template', imageCustom)\n",
    "\n",
    "    print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2\n",
      "------------------------------------------------------------\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "task2()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Gaussian Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gaussian_pyramid_opencv(image, num_levels):\n",
    "    \"\"\" Helper function to build Gaussian Pyramid using OpenCV\n",
    "    arguments:\n",
    "    image      -- Source Image\n",
    "    num_levels -- Number of Levels of Pyramid\n",
    "    \"\"\"\n",
    "    GP = image.copy()\n",
    "    gpA = [GP]\n",
    "    for i in range(num_levels):\n",
    "        GP = cv2.pyrDown(GP)\n",
    "        gpA.append(GP)\n",
    "    gpA.reverse()\n",
    "    return gpA\n",
    "\n",
    "\n",
    "def build_gaussian_pyramid(image, num_levels, sigma):\n",
    "    \"\"\" Helper function to build Custom Gaussian Pyramid\n",
    "    arguments:\n",
    "    image      -- Source Image\n",
    "    num_levels -- Number of Levels of Pyramid\n",
    "    sigma      -- S.D. for gaussian kernel\n",
    "    \"\"\"\n",
    "    image_copy = image.copy()\n",
    "    gpA = [image_copy]\n",
    "    kernel_size = 3\n",
    "    for i in range(num_levels):\n",
    "        image_blur = cv2.GaussianBlur(\n",
    "            image_copy, (kernel_size, kernel_size), sigma)\n",
    "        img_Gaussian_Blur = image_blur[::2, ::2]\n",
    "        # img_Gaussian_Blur = cv2.resize(\n",
    "        # image_blur, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "        kernel_size = kernel_size * 2 - 1\n",
    "        image_copy = img_Gaussian_Blur\n",
    "        gpA.append(img_Gaussian_Blur)\n",
    "    gpA.reverse()\n",
    "    return gpA\n",
    "\n",
    "\n",
    "def template_matching_multiple_scales(pyramid_image, pyramid_template, threshold):\n",
    "    \"\"\" Helper function to match template using Gaussian Pyramid\n",
    "    arguments:\n",
    "    pyramid_image    -- Gaussian Pyramid of Source Image\n",
    "    pyramid_template -- Gaussian Pyramid of Template\n",
    "    threshold        -- Threshold for matching\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    results = []\n",
    "    thrshld = None\n",
    "\n",
    "    # Do template match\n",
    "    for idx in range(5):\n",
    "        refimg = pyramid_image[idx]\n",
    "        tplimg = pyramid_template[idx]\n",
    "\n",
    "        # On the first level performs regular template matching.\n",
    "        if idx == 0:\n",
    "            result = cv2.matchTemplate(refimg, tplimg, cv2.TM_CCORR_NORMED)\n",
    "        # On other levels, perform pyramid transformation and template matching\n",
    "        # on the predefined ROI areas, obtained by result of the previous level.\n",
    "        else:\n",
    "            mask = cv2.pyrUp(thrshld)\n",
    "            mask8u = cv2.inRange(mask, 0, 255)\n",
    "            # contours to define the region of interest and perform template matching on the areas.\n",
    "            _, contours, _ = cv2.findContours(\n",
    "                mask8u, cv2.RETR_EXTERNAL,  cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            tH, tW = tplimg.shape[:2]\n",
    "            for cnt in contours:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                src = refimg[y:y+h+tH, x:x+w+tW]\n",
    "                result = cv2.matchTemplate(src, tplimg, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "        _, thrshld = cv2.threshold(result, threshold, 1., cv2.THRESH_TOZERO)\n",
    "        results.append(thrshld)\n",
    "\n",
    "    # Analyse the result\n",
    "    result = thrshld\n",
    "    refimg = pyramid_image[len(pyramid_image)-1]\n",
    "    tplimg = pyramid_template[len(pyramid_template)-1]\n",
    "    _, maxval, _, maxloc = cv2.minMaxLoc(result)\n",
    "    if maxval > threshold:\n",
    "        pt1 = maxloc\n",
    "        pt2 = (maxloc[0] + tplimg.shape[1], maxloc[1] + tplimg.shape[0])\n",
    "        print(\"Found the template region using OpenCV: {} => {}\".format(pt1, pt2))\n",
    "        cv2.rectangle(refimg, pt1, pt2, 255, 2)\n",
    "        displayImage(\"OpenCV Template Match\", refimg)\n",
    "    else:\n",
    "        print(\"Cannot find the template in the origin image!\")\n",
    "\n",
    "    end = time.time()\n",
    "    return (end-start)\n",
    "\n",
    "\n",
    "def task3():\n",
    "    print('Task 3')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    image = cv2.imread('../data/traffic.jpg', 0)\n",
    "    template = cv2.imread('../data/traffic-template.png', 0)\n",
    "\n",
    "    cv_pyramid = build_gaussian_pyramid_opencv(image, 4)\n",
    "    mine_pyramid = build_gaussian_pyramid(image, 4, 1)\n",
    "\n",
    "    # compare and print mean absolute difference at each level\n",
    "    for i in range(4):\n",
    "        # displayImage('CV Level' + str(i), cv_pyramid[i])\n",
    "        # displayImage('Mine Level' + str(i), mine_pyramid[i])\n",
    "        # Mean difference is pretty high, possibly because of difference in smoothing and resizing from OpenCV method\n",
    "        # Could also be because of border handling\n",
    "        print('Mean absolute difference at Level ' + str(i) + ' = ' +\n",
    "              str(np.abs(cv_pyramid[i] - mine_pyramid[i]).mean()))\n",
    "        print(\"------------------------------------------------------------\")\n",
    "\n",
    "    # fast template matching\n",
    "    pyramid_template = build_gaussian_pyramid(template, 4, 2.5)\n",
    "    result = template_matching_multiple_scales(\n",
    "        mine_pyramid, pyramid_template, 0.7)\n",
    "\n",
    "    # show result\n",
    "    print('Time taken by fast template matching: ' + str(result))\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    # performance calculation of normalised cross correlation\n",
    "    start = time.time()\n",
    "    result_ncc = normalized_cross_correlation(image, template)\n",
    "    end = time.time()\n",
    "    print('Time taken by normalised cross correlation: ' + str(end - start))\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    _, _, _, maxloc = cv2.minMaxLoc(result_ncc)\n",
    "    topLeft = maxloc\n",
    "    bottomRight = (maxloc[0] + template.shape[1],\n",
    "                   maxloc[1] + template.shape[0])\n",
    "    print(\"Found the template region using NCC: {} => {}\".format(\n",
    "        topLeft, bottomRight))\n",
    "    cv2.rectangle(image, topLeft, bottomRight, 255, 2)\n",
    "    displayImage(\"NCC Template Match\", image)\n",
    "\n",
    "    print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3\n",
      "------------------------------------------------------------\n",
      "Mean absolute difference at Level 0 = 149.6002906976744\n",
      "------------------------------------------------------------\n",
      "Mean absolute difference at Level 1 = 147.4532169117647\n",
      "------------------------------------------------------------\n",
      "Mean absolute difference at Level 2 = 139.88922334558825\n",
      "------------------------------------------------------------\n",
      "Mean absolute difference at Level 3 = 95.15230928308823\n",
      "------------------------------------------------------------\n",
      "Found the template region using OpenCV: (147, 273) => (214, 333)\n",
      "Time taken by fast template matching: 2.5911312103271484\n",
      "------------------------------------------------------------\n",
      "Time taken by normalised cross correlation: 32.59841847419739\n",
      "------------------------------------------------------------\n",
      "Found the template region using NCC: (147, 273) => (214, 333)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "task3()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivative_of_gaussian_kernel(size, sigma):\n",
    "    \"\"\" Helper function to find derivative of a kernel\n",
    "    arguments:\n",
    "    size  -- Kernel Size\n",
    "    sigma -- S.D. of the gaussian kernel\n",
    "    \"\"\"\n",
    "    # 1d kernel\n",
    "    gaussian_kernel = cv2.getGaussianKernel(size, sigma)\n",
    "    # 2d kernel\n",
    "    gaussian_kernel = np.dot(gaussian_kernel, np.transpose(gaussian_kernel))\n",
    "    # derivatives\n",
    "    dy, dx = np.gradient(gaussian_kernel)\n",
    "\n",
    "    return dx, dy\n",
    "\n",
    "\n",
    "def task4():\n",
    "    print('Task 4')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    image = cv2.imread('../data/einstein.jpeg', 0)\n",
    "\n",
    "    kernel_x, kernel_y = get_derivative_of_gaussian_kernel(5, 0.6)\n",
    "    edges_x = cv2.filter2D(image, -1, kernel_x)  # convolve with kernel_x\n",
    "    edges_y = cv2.filter2D(image, -1, kernel_y)  # convolve with kernel_y\n",
    "\n",
    "    # edges in x and y directions\n",
    "    displayImage('Edges along x-axis', edges_x)\n",
    "    displayImage('Edges along y-axis', edges_y)\n",
    "\n",
    "    magnitude = cv2.magnitude(edges_x.astype(\n",
    "        np.float), edges_y.astype(np.float))\n",
    "    direction = np.arctan2(edges_y, edges_x)  # compute edge direction\n",
    "\n",
    "    displayImage('Magnitude', magnitude.astype(np.float))\n",
    "    displayImage('Direction', direction.astype(np.float))\n",
    "\n",
    "    print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4\n",
      "------------------------------------------------------------\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "task4()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Distance Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_transform_1d(srcVec, inSize, positive_inf, negative_inf):\n",
    "    \"\"\" Distance transform of 1d function using squared distance \n",
    "    arguments:\n",
    "    srcVec -- Source 1D Array\n",
    "    inSize -- Size of Array\n",
    "    positive_inf -- Positive Infinity\n",
    "    negative_inf -- Negative Infinity\n",
    "    \"\"\"\n",
    "    distTransVec = np.zeros(srcVec.shape)\n",
    "    k = 0\n",
    "    v = np.zeros(inSize, dtype=int)\n",
    "    z = np.zeros(inSize + 1)\n",
    "    v[0] = 0\n",
    "    z[0] = negative_inf\n",
    "    z[1] = positive_inf\n",
    "\n",
    "    # Algorithm 1 from Pedro Felzenszwalb and Daniel Huttenlocher. \"Distance transforms of sampled functions\"\n",
    "    for q in range(1, inSize):\n",
    "        s = (((srcVec[q] + q * q) - (srcVec[v[k]] +\n",
    "                                     v[k] * v[k])) / (2.0 * q - 2.0 * v[k]))\n",
    "        while s <= z[k]:\n",
    "            k -= 1\n",
    "            s = (((srcVec[q] + q * q) - (srcVec[v[k]] +\n",
    "                                         v[k] * v[k])) / (2.0 * q - 2.0 * v[k]))\n",
    "        k += 1\n",
    "        v[k] = q\n",
    "        z[k] = s\n",
    "        z[k + 1] = positive_inf\n",
    "\n",
    "    k = 0\n",
    "    for q in range(inSize):\n",
    "        while z[k + 1] < q:\n",
    "            k += 1\n",
    "        distTransVec[q] = ((q - v[k]) * (q - v[k]) + srcVec[v[k]])\n",
    "    distTransVec = np.clip(distTransVec, 0, 255)\n",
    "    return distTransVec\n",
    "\n",
    "\n",
    "def l2_distance_transform_2D(edge_function, positive_inf, negative_inf):\n",
    "    \"\"\" Distance transform of 2d function using squared distance \n",
    "    arguments:\n",
    "    edge_function -- Source 2D Array\n",
    "    positive_inf  -- Positive Infinity\n",
    "    negative_inf  -- Negative Infinity\n",
    "    \"\"\"\n",
    "    rows, cols = edge_function.shape\n",
    "    f = np.zeros(max(rows, cols))\n",
    "    # transform along columns\n",
    "    for x in range(cols):\n",
    "        f = edge_function[:, x]\n",
    "        edge_function[:, x] = distance_transform_1d(\n",
    "            f, rows, positive_inf, negative_inf)\n",
    "    # transform along rows\n",
    "    for y in range(rows):\n",
    "        f = edge_function[y, :]\n",
    "        edge_function[y, :] = distance_transform_1d(\n",
    "            f, cols, positive_inf, negative_inf)\n",
    "    return edge_function\n",
    "\n",
    "\n",
    "def task5():\n",
    "    print('Task 5')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    image = cv2.imread('../data/traffic.jpg', 0)\n",
    "    displayImage('Traffic', image)\n",
    "\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 2, borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "    edges = cv2.Canny(image, 230, 350)  # compute edges\n",
    "    displayImage('Gradient Image', edges)\n",
    "\n",
    "    _, edges = cv2.threshold(\n",
    "        edges, 150, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    edge_function = edges.copy()  # prepare edges for distance transform\n",
    "\n",
    "    start_time = time.time()\n",
    "    dist_transfom_mine = l2_distance_transform_2D(\n",
    "        edge_function, np.Inf, np.NINF)\n",
    "    end_time = time.time()\n",
    "    print('Time taken by custom Distance Transform Function: ' +\n",
    "          str(round(end_time - start_time, 5)) + ' seconds')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    displayImage('Custom Distance Transform', dist_transfom_mine)\n",
    "\n",
    "    # Pedro Felzenszwalb and Daniel Huttenlocher. \"Distance transforms of sampled functions\" as per OpenCV tutorials\n",
    "    dist_transfom_cv = cv2.distanceTransform(\n",
    "        edges, cv2.DIST_L2, cv2.DIST_MASK_PRECISE)  # compute using opencv\n",
    "    cv2.normalize(dist_transfom_cv, dist_transfom_cv, 0, 1.0, cv2.NORM_MINMAX)\n",
    "    displayImage('Distance Transform Image', dist_transfom_cv)\n",
    "\n",
    "    # compare and print mean absolute difference\n",
    "    print('Mean pixel-wise difference = ' +\n",
    "          str(np.abs(dist_transfom_mine - dist_transfom_cv).mean()))\n",
    "\n",
    "    print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5\n",
      "------------------------------------------------------------\n",
      "Time taken by custom Distance Transform Function: 15.28739 seconds\n",
      "------------------------------------------------------------\n",
      "Mean pixel-wise difference = 0.0118573485\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "task5()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
